{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graphviz \n",
    "#from IPython.display import Image\n",
    "#import pydotplus\n",
    "\n",
    "\n",
    "import pandas as pd #dataframe handling library\n",
    "import numpy as np #math library\n",
    "\n",
    "import os.path #path library\n",
    "\n",
    "\n",
    "# Use bokeh to plot Interactive Plots on separate tab\n",
    "from bokeh.models.annotations import Title\n",
    "from bokeh.embed import components, file_html\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.models import ColumnDataSource, Range1d, LabelSet, Label\n",
    "from bokeh.palettes import Reds256, Category10_4,Spectral6\n",
    "from bokeh.models import HoverTool, WheelZoomTool, PanTool, BoxZoomTool, ResetTool, TapTool, SaveTool\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.signal import find_peaks #science library peak finder algorithm\n",
    "\n",
    "\n",
    "import itertools\n",
    "np.set_printoptions(precision=3, suppress=True)  # suppress scientific float notation\n",
    "\n",
    "# SETTINGS FOR NOTEBOOK\n",
    "#To show all columns\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "#pd.set_option('max_colwidth', None)\n",
    "\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "#from sklearn.externals import joblib\n",
    "from joblib import Memory\n",
    "\n",
    "#rom ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython 7.27.0\n",
      "IPython.core.release 7.27.0\n",
      "PIL 8.3.1\n",
      "PIL.Image 8.3.1\n",
      "PIL._version 8.3.1\n",
      "_csv 1.0\n",
      "_ctypes 1.1.0\n",
      "_curses b'2.2'\n",
      "_decimal 1.70\n",
      "argparse 1.1\n",
      "backcall 0.2.0\n",
      "bokeh 2.3.3\n",
      "bokeh.document.document 2.3.3\n",
      "bokeh.resources 2.3.3\n",
      "bokeh.util.version 2.3.3\n",
      "cffi 1.14.6\n",
      "colorama 0.4.4\n",
      "csv 1.0\n",
      "ctypes 1.1.0\n",
      "cycler 0.10.0\n",
      "dateutil 2.8.2\n",
      "decimal 1.70\n",
      "decorator 5.0.9\n",
      "defusedxml 0.7.1\n",
      "distutils 3.8.0\n",
      "entrypoints 0.3\n",
      "ipykernel 4.10.0\n",
      "ipykernel._version 4.10.0\n",
      "ipython_genutils 0.2.0\n",
      "ipython_genutils._version 0.2.0\n",
      "ipywidgets 7.6.3\n",
      "ipywidgets._version 7.6.3\n",
      "jedi 0.18.0\n",
      "jinja2 2.10.3\n",
      "joblib 1.0.1\n",
      "joblib.externals.cloudpickle 1.6.0\n",
      "joblib.externals.loky 2.9.0\n",
      "json 2.0.9\n",
      "jupyter_client 7.0.1\n",
      "jupyter_client._version 7.0.1\n",
      "jupyter_core 4.7.1\n",
      "jupyter_core.version 4.7.1\n",
      "kiwisolver 1.3.2\n",
      "logging 0.5.1.2\n",
      "markupsafe 2.0.1\n",
      "matplotlib 3.4.3\n",
      "nose 1.3.7\n",
      "numpy 1.21.2\n",
      "numpy.core 1.21.2\n",
      "numpy.core._multiarray_umath 3.1\n",
      "numpy.lib 1.21.2\n",
      "numpy.linalg._umath_linalg 0.1.5\n",
      "optparse 1.5.3\n",
      "pandas 0.25.3\n",
      "pandas._libs.json 1.33\n",
      "parso 0.8.2\n",
      "pexpect 4.8.0\n",
      "pickleshare 0.7.5\n",
      "pkg_resources._vendor.appdirs 1.4.3\n",
      "pkg_resources._vendor.packaging 20.4\n",
      "pkg_resources._vendor.packaging.__about__ 20.4\n",
      "pkg_resources._vendor.pyparsing 2.2.1\n",
      "pkg_resources.extern.appdirs 1.4.3\n",
      "pkg_resources.extern.packaging 20.4\n",
      "pkg_resources.extern.pyparsing 2.2.1\n",
      "platform 1.0.8\n",
      "prompt_toolkit 3.0.20\n",
      "psutil 5.8.0\n",
      "ptyprocess 0.7.0\n",
      "pygments 2.10.0\n",
      "pyparsing 2.4.7\n",
      "pytz 2021.1\n",
      "re 2.2.1\n",
      "scipy 1.7.1\n",
      "scipy._lib._uarray 0.5.1+49.g4c3f1d7.scipy\n",
      "scipy._lib.decorator 4.0.5\n",
      "scipy.integrate._dop b'$Revision: $'\n",
      "scipy.integrate._ode $Id$\n",
      "scipy.integrate._odepack  1.9 \n",
      "scipy.integrate._quadpack  1.13 \n",
      "scipy.integrate.lsoda b'$Revision: $'\n",
      "scipy.integrate.vode b'$Revision: $'\n",
      "scipy.interpolate._fitpack  1.7 \n",
      "scipy.interpolate.dfitpack b'$Revision: $'\n",
      "scipy.linalg._fblas b'$Revision: $'\n",
      "scipy.linalg._flapack b'$Revision: $'\n",
      "scipy.linalg._flinalg b'$Revision: $'\n",
      "scipy.linalg._interpolative b'$Revision: $'\n",
      "scipy.ndimage 2.0\n",
      "scipy.optimize.__nnls b'$Revision: $'\n",
      "scipy.optimize._cobyla b'$Revision: $'\n",
      "scipy.optimize._lbfgsb b'$Revision: $'\n",
      "scipy.optimize._minpack  1.10 \n",
      "scipy.optimize._slsqp b'$Revision: $'\n",
      "scipy.optimize.minpack2 b'$Revision: $'\n",
      "scipy.signal.spline 0.2\n",
      "scipy.sparse.linalg.eigen.arpack._arpack b'$Revision: $'\n",
      "scipy.sparse.linalg.isolve._iterative b'$Revision: $'\n",
      "scipy.special.specfun b'$Revision: $'\n",
      "scipy.stats.mvn b'$Revision: $'\n",
      "scipy.stats.statlib b'$Revision: $'\n",
      "six 1.16.0\n",
      "sklearn 0.21.2\n",
      "sklearn.base 0.21.2\n",
      "sklearn.utils._joblib 1.0.1\n",
      "traitlets 5.0.5\n",
      "traitlets._version 5.0.5\n",
      "urllib.request 3.8\n",
      "wcwidth 0.2.5\n",
      "yaml 5.4.1\n",
      "zlib 1.0\n",
      "zmq 22.2.1\n",
      "zmq.sugar 22.2.1\n",
      "zmq.sugar.version 22.2.1\n"
     ]
    }
   ],
   "source": [
    "# Check Versions \n",
    "\n",
    "import sys \n",
    "for name, module in sorted(sys.modules.items()): \n",
    "  if hasattr(module, '__version__'): \n",
    "    print(name, module.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Welding_model:\n",
    "  \n",
    "  def __init__(self):\n",
    "    #  Initialiaze Parameters\n",
    "    #  Replace with read statement for implementation\n",
    "    \n",
    "    self.fixed_params = {\n",
    "      'Nm_prominence':1,   \n",
    "      'forward_torque_points':30,\n",
    "      \n",
    "      'min_gap': 5,\n",
    "      'max_gap': 20,\n",
    "      'end_loc': 50,\n",
    "      'look_forward_start': 400,\n",
    "      'look_forward_finish': 600,\n",
    "      'ow_ll': 0.4,\n",
    "      'ow_ul': 1.4,\n",
    "      'iw_ll': 1.2,      \n",
    "      'iw_ul': 2.1\n",
    "      }   \n",
    "    \n",
    "    self.model_params = {\n",
    "      'force_start': [370,540],\n",
    "      'mm_iw_offset': [0.1022,0.1022],\n",
    "      'mm_ow_offset': [-0.0166,-0.0166],\n",
    "      'force_prominence': [1,1]\n",
    "      }\n",
    "    \n",
    "  def display_params(self):\n",
    "    print(self.model_params)\n",
    "    print(self.fixed_params)   \n",
    "   \n",
    "    \n",
    "  def predict(self, Spindle_Position,Spindle_Force,Spindle_Torque, head, sample_num, start_time, end_time):\n",
    "    '''\n",
    "      Main function to compute Inner and Outer Welt\n",
    "      \n",
    "      Spindle_Position(mm)   Array\n",
    "      Spindle_Force(N)       Array\n",
    "      Spindle_TorqueNm)      Array\n",
    "      head                   int\n",
    "      sample_num             int\n",
    "      start_time             time\n",
    "      end_time               time \n",
    "      \n",
    "    '''\n",
    "  \n",
    "    error_msg=\"Error --  at Initialize\"\n",
    "    try:\n",
    "    \n",
    "      # Create DataFrame from 3 input streams\n",
    "      # Add the sample number and a column to track the peaks that are identified\n",
    "      df = pd.DataFrame({'mm': Spindle_Position, 'N': Spindle_Force, 'Nm':Spindle_Torque }) \n",
    "      df['mm_avg']=df['mm'].rolling(center=True, window=10, min_periods=1).mean() \n",
    "      df['Nm_avg']=df['Nm'].rolling(center=True, window=5, min_periods=1).mean() \n",
    "      df['N_avg']=df['N'].rolling(center=True, window=5, min_periods=1).mean() \n",
    "      df['points1']=0      # for Force \n",
    "      df['points2']=0      # for Torque\n",
    "      df['points3']=0      # other\n",
    "      \n",
    "      df['sample']= sample_num\n",
    "      \n",
    "      error_msg=\"Error --  After Initialize\"\n",
    "       \n",
    "      if len(Spindle_Force) < 1000:\n",
    "        error_msg=\"Error --  # of points is too low :  \" + str(len(Spindle_Force))\n",
    "        a=1/0\n",
    "      error_msg=\"Error --  After Initialize 2\"\n",
    "      \n",
    "      # --- IW Estimate ---\n",
    "      tsi=df[df['Nm_avg']>=.05].index[0]                                       # initial point in Torque\n",
    "      df.loc[df.index==tsi , 'points2']=1\n",
    "      iws=df.loc[tsi,'mm_avg']                                                 # equivalent starting point in Position (shift to correct for Bias)\n",
    "      \n",
    "      error_msg=\"Error --  After Initialize 3\"\n",
    "      # --- Alternative method for IW estimate\n",
    "      fst=df[df['N'] > self.model_params['force_start'][head-1]].index[0]\n",
    "      df.loc[df.index==fst , 'points1']=1                                                           # force start position\n",
    "      \n",
    "      error_msg=\"Error --  After Initialize 4\"\n",
    "      #Find peaks in Torque and Force curves\n",
    "      pks_torque=find_peaks(df['Nm_avg'],prominence= self.fixed_params['Nm_prominence'])[0]\n",
    "      pks_force=find_peaks(df['N_avg'],prominence = self.model_params['force_prominence'][head-1])[0]\n",
    "      error_msg='Error --  Peaks Identified Torque: ' + str(len(pks_torque)) + '\\tForce: ' + str(len(pks_force))\n",
    "      \n",
    "      error_msg=\"Error --  After Initialize 5\"\n",
    "      max_torque=0\n",
    "      max_point=0     \n",
    "      for u in range(len(pks_torque)): \n",
    "          df.loc[df.index==pks_torque[u] , 'points2']=1   #tag the points for labeling\n",
    "          if df.loc[df.index==pks_torque[u] , 'Nm_avg'].values[0] > max_torque:\n",
    "            max_point=u\n",
    "            max_torque=df.loc[df.index==pks_torque[u] , 'Nm_avg'].values[0]\n",
    "      pt=pks_torque[max_point]\n",
    "      pt2=pks_torque[max_point+1]\n",
    "      #print(pks_torque[max_point],pt,pt2)\n",
    "      \n",
    "      \n",
    "      # Find the max Force after initial identified condition in Torqur curve\n",
    "      max_force=0\n",
    "      max_point_force=0     \n",
    "      ow_pk_index=[]\n",
    "      for u in range(len(pks_force)):\n",
    "          if pks_force[u]>=pt + self.fixed_params['forward_torque_points'] and pks_force[u]<=pt2:\n",
    "            ow_pk_index.append(pks_force[u])\n",
    "            if df.loc[df.index==pks_force[u] , 'N_avg'].values[0] > max_force:\n",
    "              max_point_force= pks_force[u]\n",
    "              max_force= df.loc[df.index==pks_force[u] , 'N_avg'].values[0]\n",
    "      #print('max force  ',max_point,max_force)\n",
    "      #print(ow_pk_index)\n",
    "      error_msg=\"Error --  After Initialize 6\"\n",
    "      \n",
    "      \n",
    "      # Use the second peak in the Torque curve to identify the final Position (in mm curve)\n",
    "      final_mm=df.loc[(pks_torque[1]+ self.fixed_params['look_forward_start']):(pks_torque[1]+ self.fixed_params['look_forward_finish'])]['mm_avg'].median()\n",
    "      #final_mm=df['mm_avg'].max()\n",
    "      \n",
    "      iwp=final_mm - iws\n",
    "      error_msg=\"Error --  After IW estimate :\" + str(iwp)\n",
    "      \n",
    "      # Identify Peak with largest drop in Force .. ad the last point to the pks_force ARRAY\n",
    "      #pks_force = np.append(pks_force , 0)\n",
    "      pks_force=np.sort(ow_pk_index)\n",
    "      \n",
    "      prev_N=0\n",
    "      max_drop=-1\n",
    "      max_drop_pos=0\n",
    "      for u in range(len(ow_pk_index)):\n",
    "          if ow_pk_index[u] >= max_point_force:                                   #search only in points past the largest pea\n",
    "            df.loc[df.index==ow_pk_index[u] , 'points1']=1\n",
    "            drop=df.loc[df.index==ow_pk_index[u] , 'N_avg'].values[0] - prev_N\n",
    "            #print('drop: ', drop,'\\tpoint and N value: ',ow_pk_index[u], df.loc[df.index==ow_pk_index[u] , 'N'].values[0])\n",
    "            if drop<max_drop:\n",
    "                max_drop=drop\n",
    "                max_drop_pos=ow_pk_index[u-1]    #take the previous point\n",
    "            prev_N=df.loc[df.index==ow_pk_index[u] , 'N_avg'].values[0]\n",
    "            \n",
    "      if max_drop_pos==0:\n",
    "        max_drop_pos=ow_pk_index[-1]\n",
    "      error_msg='Error --  Peaks Identified Torque: ' + str(len(pks_torque)) + '\\tForce Kept: ' + str(len(ow_pk_index))\n",
    "      #print('max drop poit: ', max_drop_pos)\n",
    "      \n",
    "      # Estimate OW\n",
    "      ows=df.loc[max_drop_pos,'mm_avg']                                                # use the last peak before the largest drop in the N curve\n",
    "      owp=final_mm-ows\n",
    "      \n",
    "      \n",
    "      # apply Bias correction\n",
    "      iwp = iwp +  self.model_params['mm_iw_offset'][head-1]\n",
    "      owp = owp +  self.model_params['mm_ow_offset'][head-1]\n",
    "      #print(iwp,owp)\n",
    "                                                            \n",
    "                                                                \n",
    "      df.loc[df.index==pt2+self.fixed_params['look_forward_start'] , 'points2']=1                   # end position\n",
    "      df.loc[df.index==pt+self.fixed_params['forward_torque_points'] , 'points2']=1                 # shifted start\n",
    "      df.loc[max_drop_pos , 'points3']=1                                               \n",
    "                                                                 \n",
    "\n",
    "      error_msg='Error --  during Tagging data'\n",
    "    \n",
    "      # --- Set IW, OW and Overall Flags -- if either IW or OW fail, the overall sample will fail also\n",
    "      sample_flag= 'PASS'\n",
    "      iw_flag='PASS'\n",
    "      ow_flag='PASS'\n",
    "    \n",
    "      if (iwp<self.fixed_params['iw_ll']):\n",
    "        iw_flag='LOW'\n",
    "        sample_flag= 'FAIL'\n",
    "      elif (iwp>self.fixed_params['iw_ul']):\n",
    "        iw_flag='HIGH'\n",
    "        sample_flag= 'FAIL'\n",
    "\n",
    "      if (owp<self.fixed_params['ow_ll']):\n",
    "        ow_flag='LOW'\n",
    "        sample_flag= 'FAIL'\n",
    "      elif (owp>self.fixed_params['ow_ul']):\n",
    "        ow_flag='HIGH'\n",
    "        sample_flag= 'FAIL'\n",
    "        \n",
    "    \n",
    "      # Check to ensure the data that came into the function was not truncated \n",
    "      if df.iloc[0]['N'] > self.model_params['force_start'][head-1] + 300:\n",
    "        error_msg = 'WARNING - Initial Force too high ' + str(df.iloc[0]['N'])\n",
    "      else:\n",
    "        error_msg = 'ok'\n",
    "        \n",
    "      return np.round(iwp,4),np.round(owp,4),iw_flag, ow_flag, sample_flag,self.fixed_params['iw_ll'], self.fixed_params['iw_ul'], self.fixed_params['ow_ll'], self.fixed_params['ow_ul'], \\\n",
    "              sample_num,start_time,end_time, head, df, error_msg\n",
    "    \n",
    "    except:\n",
    "      if error_msg.find('kept')>0:           #tag the points it found before checking for gap\n",
    "        for u in range(len(pks_force)-1):  \n",
    "           df.loc[df.index==pks_force[u] , 'points1']=1\n",
    "        \n",
    "      return 0.0, 0.0, 'ERROR','ERROR','ERROR',self.fixed_params['iw_ll'], self.fixed_params['iw_ul'], self.fixed_params['ow_ll'], self.fixed_params['ow_ul'], \\\n",
    "              sample_num,start_time,end_time, head, df,error_msg \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'force_start': [370, 540], 'mm_iw_offset': [0.1022, 0.1022], 'mm_ow_offset': [-0.0166, -0.0166], 'force_prominence': [1, 1]}\n",
      "{'Nm_prominence': 1, 'forward_torque_points': 30, 'min_gap': 5, 'max_gap': 20, 'end_loc': 50, 'look_forward_start': 400, 'look_forward_finish': 600, 'ow_ll': 0.4, 'ow_ul': 1.4, 'iw_ll': 1.2, 'iw_ul': 2.1}\n"
     ]
    }
   ],
   "source": [
    "iw_ow = Welding_model()\n",
    "\n",
    "iw_ow.display_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:/Users/rosen.o/OneDrive - Procter and Gamble/Smart Platforms/Welding/Files to Azure//Physical Weld Data.csv' does not exist: b'C:/Users/rosen.o/OneDrive - Procter and Gamble/Smart Platforms/Welding/Files to Azure//Physical Weld Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-66242619ecf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweld_data_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Physical Weld Data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlab_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mweld_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlab_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:/Users/rosen.o/OneDrive - Procter and Gamble/Smart Platforms/Welding/Files to Azure//Physical Weld Data.csv' does not exist: b'C:/Users/rosen.o/OneDrive - Procter and Gamble/Smart Platforms/Welding/Files to Azure//Physical Weld Data.csv'"
     ]
    }
   ],
   "source": [
    "dir_path = 'C:/Users/rosen.o/OneDrive - Procter and Gamble/Smart Platforms/Welding/Files to Azure/'\n",
    "weld_data_file='Physical Weld Data.csv'\n",
    "\n",
    "lab_results = pd.read_csv(dir_path + '/' + weld_data_file, header= 0)\n",
    "\n",
    "lab_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_data_file='combined_2.csv'\n",
    "\n",
    "detail_data = pd.read_csv(dir_path + '/' + detail_data_file, header= 0)\n",
    "\n",
    "detail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(self, Spindle_Position,Spindle_Force,Spindle_Torque, head, sample_num, start_time, end_time):\n",
    "\n",
    "sample = 10098\n",
    "selected_point = detail_data.loc[detail_data['sample'] == sample]\n",
    "selected_point.reset_index(inplace=True)\n",
    "\n",
    "hd=lab_results.loc[lab_results['Weld_ID'] == sample,'Head'].values[0]\n",
    "ts=lab_results.loc[lab_results['Weld_ID'] == sample,'Timestamp'].values[0]\n",
    "print(hd, ts)\n",
    "\n",
    "\n",
    "selected_point.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = iw_ow.predict(selected_point['Spindle_Pos'] ,selected_point['Spindle_Force'],selected_point['Spindle_Torque'] ,hd , sample, ts, ts)\n",
    "\n",
    "print(est[0:13])\n",
    "print(est[0:13], est[14])\n",
    "print(lab_results.loc[lab_results.Weld_ID==sample,['IW Avg (mm)','OW Avg (mm)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if est[14]!='aa':\n",
    "  df_out = est[13]\n",
    "  df_out.loc[df_out.points1 == 0 , \"points1\"] = np.nan\n",
    "  df_out.loc[df_out.points2 == 0 , \"points2\"] = np.nan\n",
    "  df_out.loc[df_out.points3 == 0 , \"points3\"] = np.nan\n",
    "  \n",
    "  df_out['N_points']= df_out['N'] * df_out['points1'] \n",
    "  df_out['N_points_2']= df_out['N'] * df_out['points2']\n",
    "  df_out['N_points_3']= df_out['N'] * df_out['points3']\n",
    "  \n",
    "  df_out['Nm_points']= df_out['Nm'] * df_out['points1'] \n",
    "  df_out['Nm_points_2']= df_out['Nm'] * df_out['points2'] \n",
    "  df_out['Nm_points_3']= df_out['Nm'] * df_out['points3']\n",
    "  \n",
    "  df_out['mm_points']= df_out['mm_avg'] * df_out['points1'] \n",
    "  df_out['mm_points_2']= df_out['mm_avg'] * df_out['points2'] \n",
    "  df_out['mm_points_3']= df_out['mm_avg'] * df_out['points3']\n",
    "  \n",
    "  #What should have been the position based on the lab result\n",
    "  end_mm= df_out['mm_points_2'].max()\n",
    "  #print(end_mm)\n",
    "  \n",
    "  iw_actual=lab_results.loc[lab_results['Weld_ID']==sample,'IW Avg (mm)'].values[0]\n",
    "  ow_actual=lab_results.loc[lab_results['Weld_ID']==sample,'OW Avg (mm)'].values[0]\n",
    "  iwsp=end_mm-iw_actual\n",
    "  owsp=end_mm-ow_actual\n",
    "  iwi=df_out[df_out['mm_avg']>=iwsp].index[0]\n",
    "  owi=df_out[df_out['mm_avg']>=owsp].index[0]\n",
    "\n",
    "  df_out['points4']=float(\"nan\")\n",
    "  df_out.loc[df_out.index==iwi , 'points4']=1\n",
    "  df_out.loc[df_out.index==owi , 'points4']=1\n",
    "  \n",
    "  df_out['N_points_4']= df_out['N'] * df_out['points4']\n",
    "  df_out['mm_points_4']= df_out['mm_avg'] * df_out['points4']\n",
    "  df_out['Nm_points_4']= df_out['Nm'] * df_out['points4']\n",
    "\n",
    "  start_f= df_out['N_points_4'].min()\n",
    "  print(start_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1 = figure(title=\"Nm\", x_axis_label='time', y_axis_label='Nm')\n",
    "p1.line(df.index, df['Nm'], line_width=2, color=\"blue\", legend_label=\"Nm\")\n",
    "p1.line(df.index, df['Nm_avg'], line_width=2, color=\"green\", line_dash='dotted', legend_label=\"Nm_avg\")\n",
    "p1.circle(df.index, df['Nm_points'], size=5, color=\"red\")\n",
    "p1.circle(df.index, df['Nm_points_actual'], size=7, color=\"green\")\n",
    "p1.legend.location = \"bottom_left\"\n",
    "t = Title()\n",
    "t.text = \"Sample # \" + str(sample) + \"    Nm\"\n",
    "p1.title=t\n",
    "p1.legend.click_policy=\"hide\"\n",
    "\n",
    "p2 = figure(title=\"mm\", x_axis_label='time', y_axis_label='mm')\n",
    "p2.line(df.index, df['mm'], line_width=2, color=\"blue\", legend_label=\"mm\")\n",
    "p2.line(df.index, df['mm_avg'], line_width=2, color=\"green\", line_dash='dotted', legend_label=\"mm_avg\")\n",
    "p2.circle(df.index, df['mm_points'], size=5, color=\"red\")\n",
    "p2.circle(df.index, df['mm_points_actual'], size=7, color=\"green\")\n",
    "p2.legend.location = \"bottom_left\"\n",
    "p2.legend.click_policy=\"hide\"\n",
    "\n",
    "p3 = figure(title=\"N\", x_axis_label='time', y_axis_label='N')\n",
    "p3.line(df.index, df['N'], line_width=2, color=\"blue\", legend_label=\"N\")\n",
    "p3.line(df.index, df['N_avg'], line_width=2, color=\"green\", line_dash='dotted', legend_label=\"N_avg\")\n",
    "p3.circle(df.index, df['N_points'], size=5, color=\"red\")\n",
    "p3.circle(df.index, df['N_points_actual'], size=7, color=\"green\")\n",
    "p3.legend.location = \"bottom_left\"\n",
    "p3.legend.click_policy=\"hide\"\n",
    "\n",
    "\n",
    "grid = gridplot([[p1,p2,p3]], plot_width=500, plot_height=500)\n",
    "show(grid)"
   ]
  }
 ],
 "metadata": {
  "autoplay": {
   "autoRun": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
